<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Racial bias in AI</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/ninjutsu.css" rel="stylesheet" />
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="../../../theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: top, left, title-slide

# Racial bias in AI
### 

---


class: inverse









&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 1.2rem;
    padding: 1em 4em 1em 4em;
}
&lt;/style&gt;

## Outline

#### Demystifying AI

What is it? What's *really* new about it?

#### Racial bias in AI

Examples in healthcare, policing, commerce

#### Useful concepts

Fairness, biased data, biased models, biased systems

#### Actions

Tech "solutions," inclusion, democratization, power

---
class: inverse

# What is AI?

(this might be the most controversial part of the talk)

$$
\text{AI} \approx \text{machine learning} \approx \text{regression}
$$

Predictions from lots of "similar" examples. From [Stanford](http://cs231n.stanford.edu/):

![](../imagetraining.png)

---

![](https://miro.medium.com/max/1826/1*9cdCxwJO-mgpN7t5tfZODQ.png)

"Examples" don't have to be images, this generalizes to anything that can be measured and transformed into data

---

## Historical

### Early computer era (~50 years ago)

Regression (prediction recipe) -- decision trees -- low dimensional smoothing

### Internet era (~20 years ago)

Machine learning -- "black box" (more complex) algorithms

### Big data, 3rd wave of AI (~10 years ago)

Network architecture (depth) -- datafication of images, etc

---

### Classic methods

#### Regression

- Predictor variables in the dataset: `\(x_1, x_2, \ldots, x_p\)`
- Coefficients/**parameters**, unknown: `\(\beta_1, \beta_2, \ldots, \beta_p\)`
- Outcome variable, also in data: `\(y\)`
- Algorithm inputs the data, outputs: estimated parameters, predictions of `\(y\)` using "recipe" or "weighted" combination

$$
\beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p
$$

#### Decision trees (e.g. vaccine eligibility in the UK)

- If `Age &gt;= 40` then `yes`, otherwise `continue`
- If `HighRisk == TRUE` then `yes`, otherwise `continue`
- If `Job == CareWorker` then `yes`, otherwise `no`

---

### Present day methods

.pull-left[
![](https://joshualoftus.com/ml4ds/07-nonlinear/slides/gtrendDL.png)
]
.pull-right[
From [Computer Age Statistical Inference](https://web.stanford.edu/~hastie/CASI/):
![](https://joshualoftus.com/ml4ds/07-nonlinear/slides/CASI18.3.png)
]

Non-linear, deep (multiple) composition of functions


---

## Consistent trends

- Larger datasets, faster computation, more parameters

1801: [Gauss's](https://sites.math.rutgers.edu/~cherlin/History/Papers1999/weiss.html) first use of regression, ~5 parameters

2000s: models with ~thousands of parameters (e.g. [lasso](https://pubmed.ncbi.nlm.nih.gov/?term=lasso+regression))

2012: image model [AlexNet](https://en.wikipedia.org/wiki/AlexNet) uses ~61 million parameters

2020: language model [GPT-3](https://en.wikipedia.org/wiki/GPT-3) uses ~175 billion parameters


- Focus on improving prediction accuracy, sacrifice explainability to (non-expert) human audiences

- More categories of things analyzed as data

- More kinds of tasks "automated" (possibly: outsourced)

---

### Programming

Code: human readable `\(\to\)` machine executable `\(\to\)` output

#### Deterministic programming

.pull-left[

```r
print("hello world")
```

```
## [1] "hello world"
```

]
.pull-right[

```r
round(1 / (0:3), 3)
```

```
## [1]   Inf 1.000 0.500 0.333
```
]

Programmers know what to expect (but see: debugging)

#### Stochastic programming

Inputs include a dataset

---

### Models



#### Classic

Human readable models

#### ML / AI

How to "read" a model with millions of parameters?

---

### Dangers of opacity

[Reuters](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G), in 2018:

![Amazon scraps secret AI recruiting tool that showed bias against women](./../amazonhiring.png)

&gt; Amazon’s system **taught itself** that male candidates were preferable. It penalized resumes that included the word “women’s,” as in “women’s chess club captain.” And it downgraded graduates of two all-women’s colleges, according to people familiar with the matter.



---

### Auditing opaque models: accuracy

From the [Gender shades](http://gendershades.org/) project

![](../gendershades.png)
---
class: inverse, center, middle

![](../gendershades2.png)

---
class: inverse

# More motivating examples

Slides on

- Health: Obermeyer et al
- Policing: Lum and Isaacs, ProPublica
- Consumption: Amazon
- Labor: ghost work?
- Environment: e.g. cobalt extraction, also labor

(anatomy of AI / global picture)

---

### Pre-trial detention risk scores

.pull-left[
![](../compas_logit.png)
]
.pull-right[
![](../propublicalogo.png)

![](../propublica.png)

![](../propublica2.png)

![](../propublica3.png)
]

---

The [hope](https://www.kqed.org/education/507247/can-algorithms-help-wind-down-mass-incarceration): could more accurate risk assessments reduce incarceration, and maybe even reduce racial bias?

The reality: proprietary, opaque algorithms

![](../prop25.png)

- Multibillion-dollar bail industry spent $10 million opposing

- Did voters understand what these algorithms would do?

---

"Algorithm does not *explicitly* use race" -- in an unfair system other things can correlate with race, e.g. previous convictions. From [Lum and Isaac (2016)](https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1740-9713.2016.00960.x)

---

.pull-left[
![](../lumisaac1.jpg)
]

.pull-right[
![](../lumisaac2.jpg)
]

---

### (Sampling) bias in healthcare patient data

.pull-left[

![](../obermeyer.PNG)

]
.pull-right[

[Obermeyer et al (2019)](https://science.sciencemag.org/content/366/6464/447.editor-summary)

- Algorithm assigns risk scores by **predicting healthcare costs** from patient records
- Underestimates risk of health conditions for black patients compared to white patients
- **Adjusting algorithm** to close the gap results in ~2.5x black patients receiving more care

]

---

Scaling up: cheaper, faster, maybe more accurate than humans

Tech solution: maybe fairer than humans

Key drawback: maybe *this task should not be scaled up* (or done at all)?

---
class: inverse

## Useful concepts

And how they relate to previous examples

---

.pull-left[

]
.pull-right[

]

---

How to think like a statistician about AI

- Model is always wrong
- Data is (almost) always biased
- Measurement

---

edit this

### Interventions, counterfactuals, thought experiments

- Pearl's [ladder of causation](https://en.wikipedia.org/wiki/Causal_model#Ladder_of_causation) level 2

Intervention, action, manipulation, policy change

*What will (or is more likely to) happen if...*

- But we can also go to level 3

Counterfactuals, potential histories(?)

*What would have (been more likely to have) happened if...*

- Thought experiments

Models as thinking tools, *over-simplified models as diagnostics for more realistic ones*

---

### Statistical wisdom: models as (thinking) tools

.pull-left[
![](https://upload.wikimedia.org/wikipedia/commons/a/a2/GeorgeEPBox.jpg)
[George Box](https://en.wikipedia.org/wiki/George_E._P._Box)
]

.pull-right[

&gt; [All models are wrong](All_models_are_wrong) but some are useful

therefore,

&gt; ... the scientist must be alert to what is **importantly wrong**

&gt; ... **cannot obtain a "correct" one** by excessive elaboration

]

---

What's **important** and what's **useful**?

- to who?
- for what?

---
class: inverse

# Changing the world

There are real opportunities to make *fast/cheap* progress by changing algorithms

But we should not neglect more important actions

- Democratizing data
- Decolonial AI
- Irwin Bross: scientist or shoe clerk? Need professional organization to back up an individual (data) scientist so they can act on conscience

---

https://www.ictworks.org/barriers-data-sharing-african-artificial-intelligence-solutions/#.YJF6csCSk2w

---

## Regulation

Public/worker desire for regulation https://www.cnet.com/news/even-silicon-valley-workers-want-more-regulation-of-the-tech-industry/

Potential drawbacks: legal/technical arms races, regulatory capture

(necessary but not sufficient)

---

- [Black in AI](https://blackinai.github.io/#/about) founded in 2017
- Examples of tech workers organizing
- Examples of gig workers organizing

Obstacles: opposition, knowledge

Google firing AI ethics researchers



---

Changing the objective function

https://en.wikipedia.org/wiki/Twelve_leverage_points

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"highlightSpans": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
(function(time) {
  var d2 = function(number) {
    return ('0' + number).slice(-2); // left-pad 0 to minutes/seconds
  },

  time_format = function(total) {
    var secs = Math.abs(total) / 1000;
    var h = Math.floor(secs / 3600);
    var m = Math.floor(secs % 3600 / 60);
    var s = Math.round(secs % 60);
    var res = d2(m) + ':' + d2(s);
    if (h > 0) res = h + ':' + res;
    return res;  // [hh:]mm:ss
  },

  slide_number_div = function(i) {
    return document.getElementsByClassName('remark-slide-number').item(i);
  },

  current_page_number = function(i) {
    return slide_number_div(i).firstChild.textContent;  // text "i / N"
  };

  var timer = document.createElement('span'); timer.id = 'slide-time-left';
  var time_left = time, k = slideshow.getCurrentSlideIndex(),
      last_page_number = current_page_number(k);

  setInterval(function() {
    time_left = time_left - 1000;
    timer.innerHTML = ' ' + time_format(time_left);
    if (time_left < 0) timer.style.color = 'red';
  }, 1000);

  slide_number_div(k).appendChild(timer);

  slideshow.on('showSlide', function(slide) {
    var i = slide.getSlideIndex(), n = current_page_number(i);
    // reset timer when a new slide is shown and the page number is changed
    if (last_page_number !== n) {
      time_left = time; last_page_number = n;
      timer.innerHTML = ' ' + time_format(time); timer.style.color = null;
    }
    slide_number_div(i).appendChild(timer);
  });
})(59000);
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
