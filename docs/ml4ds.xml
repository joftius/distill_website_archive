<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>Neurath's Speedboat</title>
    <link>http://joshualoftus.com/</link>
    <atom:link href="http://joshualoftus.com/ml4ds.xml" rel="self" type="application/rss+xml"/>
    <description>Academic website and blog of Joshua Loftus
</description>
    <generator>Distill</generator>
    <lastBuildDate>Mon, 01 Mar 2021 00:00:00 +0000</lastBuildDate>
    <item>
      <title>Regularization and validation</title>
      <dc:creator>Joshua Loftus</dc:creator>
      <link>http://joshualoftus.com/ml4ds/06-regularization</link>
      <description>When optimizing an ML model there are a variety of strategies to improve generalization from the training data. We can add a complexity penalty to the loss function, and we can evaluate the loss function on validation data.</description>
      <guid>http://joshualoftus.com/ml4ds/06-regularization</guid>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Optimization and overfitting</title>
      <dc:creator>Joshua Loftus</dc:creator>
      <link>http://joshualoftus.com/ml4ds/05-optimization</link>
      <description>Optimization is about finding the best model. With greater model complexity it becomes increasingly important to avoid overfitting: finding a model that is best for one specific dataset but does not generalize well to others.</description>
      <guid>http://joshualoftus.com/ml4ds/05-optimization</guid>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Classification</title>
      <dc:creator>Joshua Loftus</dc:creator>
      <link>http://joshualoftus.com/ml4ds/04-classification</link>
      <description>Categorical or qualitative outcome variables are ubiquitous. We review some supervised learning methods for classification, and see how these may be applied to observational causal inference.</description>
      <guid>http://joshualoftus.com/ml4ds/04-classification</guid>
      <pubDate>Mon, 08 Feb 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Multiple regression and causality</title>
      <dc:creator>Joshua Loftus</dc:creator>
      <link>http://joshualoftus.com/ml4ds/03-causality</link>
      <description>Multiple linear regression does not, by default, tell us anything about causality. But with the right data and careful interpretation we might be able to learn some causal relationships.</description>
      <guid>http://joshualoftus.com/ml4ds/03-causality</guid>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Linear regression</title>
      <dc:creator>Joshua Loftus</dc:creator>
      <link>http://joshualoftus.com/ml4ds/02-linear-regression</link>
      <description>Reviewing linear regression and framing it as a prototypical example and source of intuition for other machine learning methods.</description>
      <guid>http://joshualoftus.com/ml4ds/02-linear-regression</guid>
      <pubDate>Mon, 25 Jan 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Introduction and foundations</title>
      <dc:creator>Joshua Loftus</dc:creator>
      <link>http://joshualoftus.com/ml4ds/01-introduction-foundations</link>
      <description>A brief introduction to the course, preview of things to come, and some foundational background material.</description>
      <guid>http://joshualoftus.com/ml4ds/01-introduction-foundations</guid>
      <pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://joshualoftus.com/ml4ds/01-introduction-foundations/slides/01-2-foundations_files/figure-html/gapminder-loess-1.png" medium="image" type="image/png"/>
    </item>
  </channel>
</rss>
