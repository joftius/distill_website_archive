---
title: "Introduction and foundations"
description: |
  A brief introduction to the course, preview of things to come, and some foundational background material.
author:
  - name: Joshua Loftus
date: 01-15-2021
output:
  distill::distill_article:
    self_contained: false
preview: https://joshualoftus.com/ml4ds/01-introduction-foundations/slides/01-2-foundations_files/figure-html/gapminder-loess-1.png
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE)
library(tidyverse)
library(knitr)
library(gapminder)
theme_set(theme_minimal(base_size = 22))
```

## What is machine learning?

This week introduced some of the key conceptual themes in machine learning. Two simple examples illustrated different strategies for building more complex models:

- increasing complexity of the function class, for example by allowing functions to fit flexibly/locally to different subsets of the data
- increasing the dimension of predictors (while otherwise keeping the function class fixed)

[Model complexity](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) relates to the [bias-variance trade-off](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff): more complexity *typically* results in lower bias and higher variance.

```{r, figure, fig.show = "hold", out.width = "50%", fig.align = "default"}
include_graphics("https://joshualoftus.com/ml4ds/01-introduction-foundations/slides/01-2-foundations_files/figure-html/gapminder-lm-1.png")
include_graphics("https://joshualoftus.com/ml4ds/01-introduction-foundations/slides/01-2-foundations_files/figure-html/gapminder-loess-1.png")
```

Increasing complexity also (essentially always) results in a lower mean-squared error if the MSE is calculated on the same dataset that was used to fit the model. But if the MSE is calculated on a different dataset this is no longer true, and more complexity may result in a larger MSE. 

Why should we evaluate model fit (like MSE) on a different dataset than the one used to fit the model? First, if we evaluate it on the same dataset instead, then such an evaluation will always prefer greater complexity until the model fully saturates the data. In this case there was nothing gained from using a model--we have only created a [map as large as the entire territory](https://en.wikipedia.org/wiki/On_Exactitude_in_Science#Influences_and_legacy). Second, if our purpose in using a model is to describe some *stable* aspect of the world, then we would hope that such a model's fit would not immediately fail if the time or context of the data collection is slightly different.

Since these concepts are so central to machine learning we will return to them several times through the term and understand them through more examples and some mathematical derivations.

## Slides and notebooks

[Slides](slides/01-1-introduction.html) for first video

[Notebook](notebooks/gapminder.html) for `gapminder` example

[Notebook](notebooks/candy.html) for `candy` example

[Slides](slides/01-2-foundations.html) for last video

[Notebook](notebooks/seminar.html) from seminar
